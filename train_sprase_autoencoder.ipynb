{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNNZ4yCGndDA"
      },
      "source": [
        "# load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPTQLzRQncbM",
        "outputId": "ce5de1da-8c41-4e9a-a775-ab1462ea6b01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Dataset URL: https://www.kaggle.com/datasets/jessicali9530/celeba-dataset\n",
            "License(s): other\n",
            "celeba-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  celeba-dataset.zip\n",
            "replace celeba-dataset/img_align_celeba/img_align_celeba/000001.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "\n",
        "api_token = {\"username\":\"username\",\"key\":\"api-key\"}\n",
        "\n",
        "import json\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d jessicali9530/celeba-dataset\n",
        "\n",
        "!unzip celeba-dataset.zip -d celeba-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGkEETsWnV0B"
      },
      "source": [
        "# Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QLFXUwvClsOr",
        "outputId": "b15fb171-16a1-45e6-ef81-063dafa7fefa"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "mount failed",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8c3890815319>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         )\n\u001b[0;32m--> 277\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "import torch\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_1X_ggvqDWz",
        "outputId": "fa5e74c7-aa49-42cb-aed3-7c5fc22c8cf4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-2-7018ea67a721>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\"/content/tmp_checkpoint10(11).pt\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "2048"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = torchvision.models.resnet50()\n",
        "# Model\n",
        "n_classes = 2\n",
        "model = torchvision.models.resnet50(pretrained=True)\n",
        "d = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(d, n_classes)\n",
        "\n",
        "checkpoint = torch.load(\"/content/tmp_checkpoint10(11).pt\")\n",
        "model.load_state_dict(checkpoint)\n",
        "\n",
        "model.cuda()\n",
        "model.fc.in_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yTQxifErTJa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OElzLFP6sYC4"
      },
      "source": [
        "# Select last layer out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOYuDbHiJple",
        "outputId": "268d05f3-dcfd-487e-e8be-8b491df89bd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'deep_feature_reweighting' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/PolinaKirichenko/deep_feature_reweighting.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWI6kAkkJ7Q_"
      },
      "outputs": [],
      "source": [
        "!cp deep_feature_reweighting/celeba_metadata.csv celeba-dataset/img_align_celeba/metadata.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_WHd-vSKOby"
      },
      "outputs": [],
      "source": [
        "## MY\n",
        "\n",
        "\"\"\"\n",
        "Train a Sparse AutoEncoder model\n",
        "\n",
        "Run on a macbook on a Shakespeare dataset as\n",
        "python train.py --dataset=shakespeare_char --gpt_ckpt_dir=out_sc_1_2_32 --eval_iters=1 --eval_batch_size=16 --batch_size=128 --device=cpu --eval_interval=100 --n_features=1024 --resampling_interval=150 --wandb_log=True\n",
        "\"\"\"\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "\n",
        "## hyperparameters\n",
        "\n",
        "# training\n",
        "n_features = 8096\n",
        "batch_size = 128 # batch size for autoencoder training\n",
        "l1_coeff = 3e-3\n",
        "learning_rate = 3e-4\n",
        "resampling_interval = 25000 # number of training steps after which neuron resampling will be performed\n",
        "num_resamples = 4 # number of times resampling is to be performed; it is done 4 times in Anthropic's paper\n",
        "resampling_data_size = 819200\n",
        "# evaluation\n",
        "eval_batch_size = 16 # batch size (number of GPT contexts) for evaluation\n",
        "eval_iters = 200 # number of iterations in the evaluation loop\n",
        "eval_interval = 1000 # number of training steps after which the autoencoder is evaluated\n",
        "# I/O\n",
        "save_checkpoint = True # whether to save model, optimizer, etc or not\n",
        "save_interval = 10000 # number of training steps after which a checkpoint will be saved\n",
        "out_dir = 'out' # directory containing trained autoencoder model weights\n",
        "# wandb logging\n",
        "wandb_log = True\n",
        "# system\n",
        "device = 'cuda'\n",
        "# reproducibility\n",
        "seed = 1442\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "config_keys = [k for k,v in globals().items() if not k.startswith('_') and isinstance(v, (int, float, bool, str))]\n",
        "#exec(open('configurator.py').read()) # overrides from command line or config file\n",
        "config = {k: globals()[k] for k in config_keys} # will be useful for logging\n",
        "# -----------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7_BTOsCsovR",
        "outputId": "e600334a-49cf-41ea-9b85-4828ddc0161c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "202599\n",
            "162770\n",
            "202599\n",
            "19962\n",
            "202599\n",
            "19867\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from deep_feature_reweighting.wb_data import WaterBirdsDataset, get_loader, get_transform_cub, log_data\n",
        "\n",
        "basedir = '/content/celeba-dataset/img_align_celeba/'\n",
        "test_wb_dir='/content/celeba-dataset/img_align_celeba/'\n",
        "\n",
        "# Data\n",
        "target_resolution = (224, 224)\n",
        "train_transform = get_transform_cub(target_resolution=target_resolution, train=True, augment_data=None)\n",
        "test_transform = get_transform_cub(target_resolution=target_resolution, train=False, augment_data=None)\n",
        "\n",
        "\n",
        "trainset = WaterBirdsDataset(basedir=basedir, split=\"train\", transform=train_transform)\n",
        "testset_dict = {\n",
        "    'wb': WaterBirdsDataset(basedir=test_wb_dir, split=\"test\", transform=test_transform),\n",
        "    'wb_val': WaterBirdsDataset(basedir=test_wb_dir, split=\"val\", transform=test_transform),\n",
        "}\n",
        "''\n",
        "loader_kwargs = {'batch_size': batch_size, 'num_workers': 4, 'pin_memory': True}\n",
        "train_loader = get_loader(trainset, reweight_groups=None,\n",
        "                          reweight_classes=None, reweight_places=None, train=True, **loader_kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVRFL6y8s6Uz"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "\n",
        "def get_embed(m, x):\n",
        "    x = m.conv1(x)\n",
        "    x = m.bn1(x)\n",
        "    x = m.relu(x)\n",
        "    x = m.maxpool(x)\n",
        "\n",
        "    x = m.layer1(x)\n",
        "    x = m.layer2(x)\n",
        "    x = m.layer3(x)\n",
        "    x = m.layer4(x)\n",
        "\n",
        "    x = m.avgpool(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iCiQ72Ls_NO"
      },
      "outputs": [],
      "source": [
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkIwWelZMxTD"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This file defines an AutoEncoder class, which also contains an implementation of neuron resampling.\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, n_inputs: int, n_latents: int, lam: float = 0.003, resampling_interval: int = 25000):\n",
        "        \"\"\"\n",
        "        n_input: Number of inputs\n",
        "        n_latents: Number of neurons in the hidden layer\n",
        "        lam: L1-coefficient for Sparse Autoencoder\n",
        "        resampling_interval: Number of training steps after which dead neurons will be resampled\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.n_inputs, self.n_latents = n_inputs, n_latents\n",
        "        self.encoder = nn.Linear(n_inputs, n_latents)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.decoder = nn.Linear(n_latents, n_inputs)\n",
        "        self.lam = lam\n",
        "        self.resampling_interval = resampling_interval\n",
        "        self.dead_neurons = None\n",
        "        self.normalize_decoder_columns()\n",
        "\n",
        "    def forward(self, x):\n",
        "        latents = self.encode(x)\n",
        "        reconstructed = self.decode(latents)\n",
        "        loss = self.calculate_loss(x, latents, reconstructed)\n",
        "\n",
        "        if self.training:\n",
        "            return {'loss': loss, 'latents': latents}\n",
        "        else:\n",
        "            return {\n",
        "                'loss': loss,\n",
        "                'latents': latents,\n",
        "                'reconst_acts': reconstructed,\n",
        "                'mse_loss': self.mse_loss(reconstructed, x),\n",
        "                'l1_loss': self.l1_loss(latents)\n",
        "            }\n",
        "\n",
        "    def encode(self, x):\n",
        "        bias_corrected_input = x - self.decoder.bias\n",
        "        return self.relu(self.encoder(bias_corrected_input))\n",
        "\n",
        "    def decode(self, encoded):\n",
        "        return self.decoder(encoded)\n",
        "\n",
        "    def calculate_loss(self, x, encoded, reconstructed):\n",
        "        mse_loss = self.mse_loss(reconstructed, x)\n",
        "        l1_loss = self.l1_loss(encoded)\n",
        "        return mse_loss + self.lam * l1_loss\n",
        "\n",
        "    def mse_loss(self, reconstructed, original):\n",
        "        return F.mse_loss(reconstructed, original)\n",
        "\n",
        "    def l1_loss(self, encoded):\n",
        "        return F.l1_loss(encoded, torch.zeros_like(encoded), reduction='sum') / encoded.shape[0]\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def get_feature_activations(self, inputs, start_idx, end_idx):\n",
        "        \"\"\"\n",
        "        Computes the activations of a subset of features in the hidden layer.\n",
        "\n",
        "        :param inputs: Input tensor of shape (..., n) where n = d_MLP. It includes batch dimensions.\n",
        "        :param start_idx: Starting index (inclusive) of the feature subset.\n",
        "        :param end_idx: Ending index (exclusive) of the feature subset.\n",
        "\n",
        "        Returns the activations for the specified feature range, reducing computation by\n",
        "        only processing the necessary part of the network's weights and biases.\n",
        "        \"\"\"\n",
        "        adjusted_inputs = inputs - self.decoder.bias  # Adjust input to account for decoder bias\n",
        "        weight_subset = self.encoder.weight[start_idx:end_idx, :].t()  # Transpose the subset of weights\n",
        "        bias_subset = self.encoder.bias[start_idx:end_idx]\n",
        "\n",
        "        activations = self.relu(adjusted_inputs @ weight_subset + bias_subset)\n",
        "\n",
        "        return activations\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def normalize_decoder_columns(self):\n",
        "        \"\"\"\n",
        "        Normalize the decoder's weight vectors to have unit norm along the feature dimension.\n",
        "        This normalization can help in maintaining the stability of the network's weights.\n",
        "        \"\"\"\n",
        "        self.decoder.weight.data = F.normalize(self.decoder.weight.data, dim=0)\n",
        "\n",
        "    def remove_parallel_component_of_decoder_grad(self):\n",
        "        \"\"\"\n",
        "        Remove the component of the gradient parallel to the decoder's weight vectors.\n",
        "        \"\"\"\n",
        "        unit_weights = F.normalize(self.decoder.weight, dim=0) # \\hat{b}\n",
        "        proj = (self.decoder.weight.grad * unit_weights).sum(dim=0) * unit_weights\n",
        "        self.decoder.weight.grad = self.decoder.weight.grad - proj\n",
        "\n",
        "    @staticmethod\n",
        "    def is_dead_neuron_investigation_step(step, resampling_interval, num_resamples):\n",
        "        \"\"\"\n",
        "        Determine if the current step is the start of a phase for investigating dead neurons.\n",
        "        According to Anthropic's specified policy, it occurs at odd multiples of half the resampling interval.\n",
        "        \"\"\"\n",
        "        return (step > 0) and step % (resampling_interval // 2) == 0 and (step // (resampling_interval // 2)) % 2 != 0 and step < resampling_interval * num_resamples\n",
        "\n",
        "    @staticmethod\n",
        "    def is_within_neuron_investigation_phase(step, resampling_interval, num_resamples):\n",
        "        \"\"\"\n",
        "        Check if the current step is within a phase where active neurons are investigated.\n",
        "        This phase occurs in intervals defined in the specified range, starting at odd multiples of half the resampling interval.\n",
        "        \"\"\"\n",
        "        return any(milestone - resampling_interval // 2 <= step < milestone\n",
        "                   for milestone in range(resampling_interval, resampling_interval * (num_resamples + 1), resampling_interval))\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def initiate_dead_neurons(self):\n",
        "        self.dead_neurons = set(range(self.n_latents))\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def update_dead_neurons(self, latents):\n",
        "        \"\"\"\n",
        "        Update the set of dead neurons based on the current feature activations.\n",
        "        If a neuron is active (has non-zero activation), it is removed from the dead neuron set.\n",
        "        \"\"\"\n",
        "        active_neurons = torch.nonzero(torch.count_nonzero(latents, dim=0), as_tuple=False).view(-1)\n",
        "        self.dead_neurons.difference_update(active_neurons.tolist())\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def resample_dead_neurons(self, data, optimizer, batch_size=8192):\n",
        "        \"\"\"\n",
        "        Resample the dead neurons by resetting their weights and biases based on the characteristics\n",
        "        of active neurons. Proceeds only if there are dead neurons to resample.\n",
        "        \"\"\"\n",
        "        if not self.dead_neurons:\n",
        "            return\n",
        "\n",
        "        device = self._get_device()\n",
        "        dead_neurons_t, alive_neurons = self._get_neuron_indices()\n",
        "        average_enc_norm = self._compute_average_norm_of_alive_neurons(alive_neurons)\n",
        "        probs = self._compute_loss_probabilities(data, batch_size, device)\n",
        "        selected_examples = self._select_examples_based_on_probabilities(data, probs)\n",
        "\n",
        "        self._resample_neurons(selected_examples, dead_neurons_t, average_enc_norm, device)\n",
        "        self._update_optimizer_parameters(optimizer, dead_neurons_t)\n",
        "\n",
        "        print('Dead neurons resampled successfully!')\n",
        "        self.dead_neurons = None\n",
        "\n",
        "    def _get_device(self):\n",
        "        return next(self.parameters()).device\n",
        "\n",
        "    def _get_neuron_indices(self):\n",
        "        dead_neurons_t = torch.tensor(list(self.dead_neurons), device=self._get_device())\n",
        "        alive_neurons = torch.tensor([i for i in range(self.n_latents) if i not in self.dead_neurons], device=self._get_device())\n",
        "        return dead_neurons_t, alive_neurons\n",
        "\n",
        "    def _compute_average_norm_of_alive_neurons(self, alive_neurons):\n",
        "        return torch.linalg.vector_norm(self.encoder.weight[alive_neurons], dim=1).mean()\n",
        "\n",
        "    def _compute_loss_probabilities(self, data, batch_size, device):\n",
        "        num_batches = (len(data) + batch_size - 1) // batch_size\n",
        "        probs = torch.zeros(len(data), device=device)\n",
        "        for i in range(num_batches):\n",
        "            batch_slice = slice(i * batch_size, (i + 1) * batch_size)\n",
        "            x_batch = data[batch_slice].to(device)\n",
        "            probs[batch_slice] = self._compute_batch_loss_squared(x_batch)\n",
        "        return probs.cpu()\n",
        "\n",
        "    def _compute_batch_loss_squared(self, x_batch):\n",
        "        latents = self.encode(x_batch)\n",
        "        reconst_acts = self.decode(latents)\n",
        "        mselosses = F.mse_loss(reconst_acts, x_batch, reduction='none').sum(dim=1)\n",
        "        l1losses = F.l1_loss(latents, torch.zeros_like(latents), reduction='none').sum(dim=1)\n",
        "        return (mselosses + self.lam * l1losses).square()\n",
        "\n",
        "    def _select_examples_based_on_probabilities(self, data, probs):\n",
        "        selection_indices = torch.multinomial(probs, num_samples=len(self.dead_neurons))\n",
        "        return data[selection_indices].to(dtype=torch.float32)\n",
        "\n",
        "    def _resample_neurons(self, examples, dead_neurons_t, average_enc_norm, device):\n",
        "        examples_unit_norm = F.normalize(examples, dim=1).to(device)\n",
        "        self.decoder.weight[:, dead_neurons_t] = examples_unit_norm.T\n",
        "\n",
        "        # Renormalize examples to have a certain norm and reset encoder weights and biases\n",
        "        adjusted_examples = examples_unit_norm * average_enc_norm * 0.2\n",
        "        self.encoder.weight[dead_neurons_t] = adjusted_examples\n",
        "        self.encoder.bias[dead_neurons_t] = 0\n",
        "\n",
        "    def _update_optimizer_parameters(self, optimizer, dead_neurons_t):\n",
        "        for i, param in enumerate(optimizer.param_groups[0]['params']):\n",
        "            param_state = optimizer.state[param]\n",
        "            if i in [0, 1]:  # Encoder weights and biases\n",
        "                param_state['exp_avg'][dead_neurons_t] = 0\n",
        "                param_state['exp_avg_sq'][dead_neurons_t] = 0\n",
        "            elif i == 2:  # Decoder weights\n",
        "                param_state['exp_avg'][:, dead_neurons_t] = 0\n",
        "                param_state['exp_avg_sq'][:, dead_neurons_t] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1Y11P9SKqym"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(seed)\n",
        "# initiating ResourceLoader in training mode loads Transformer checkpoint, text data, and autoencoder data\n",
        "# resourceloader = ResourceLoader(\n",
        "#                             dataset=dataset,\n",
        "#                             gpt_ckpt_dir=gpt_ckpt_dir,\n",
        "#                             device=device,\n",
        "#                             mode=\"train\",\n",
        "#                             )\n",
        "\n",
        "# gpt = resourceloader.transformer # TODO: either it should be called transformer or gpt\n",
        "autoencoder = AutoEncoder(n_inputs = model.fc.in_features,\n",
        "                            n_latents = n_features,\n",
        "                            lam = l1_coeff,\n",
        "                            resampling_interval = resampling_interval).to(device)\n",
        "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "o97jRR05NN9h",
        "outputId": "8e4d084f-ed95-4fdd-84f5-01039dec6cf1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1272 [00:05<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entering evaluation mode at step = 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'mse_loss'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-db3ac781bd87>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m   \u001b[0;31m#     log_dict['losses/reconstructed_nll'] += reconstructed_nll.item()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mlog_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'losses/autoencoder_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mautoencoder_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mlog_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'losses/reconstruction_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mautoencoder_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mse_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mlog_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'losses/l1_norm'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mautoencoder_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'l1_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m#     log_dict['losses/nll_score'] += (nll_loss - reconstructed_nll).item()/(nll_loss - ablated_loss).item()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'mse_loss'"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "############## TRAINING LOOP ###############\n",
        "start_time = time.time()\n",
        "#num_steps = len(train_loader)  // batch_size\n",
        "step = 0\n",
        "num_steps = len(train_loader)\n",
        "for batch in tqdm.tqdm(train_loader):\n",
        "    x, y, g, p = batch\n",
        "    x, y, p = x.cuda(), y.cuda(), p.cuda()\n",
        "\n",
        "    #batch = resourceloader.get_autoencoder_data_batch(step, batch_size=batch_size)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    autoencoder_output = autoencoder(get_embed(model, x)) # f has shape (batch_size, n_features)\n",
        "    autoencoder_output['loss'].backward()\n",
        "\n",
        "    # remove component of gradient parallel to weight\n",
        "    autoencoder.remove_parallel_component_of_decoder_grad()\n",
        "    optimizer.step()\n",
        "\n",
        "    # periodically update the norm of dictionary vectors to ensure they stay close to 1.\n",
        "    if step % 1000 == 0:\n",
        "        autoencoder.normalize_decoder_columns()\n",
        "\n",
        "    ## ------------ perform neuron resampling ----------- ######\n",
        "    # check if we should start investigating dead/alive neurons at this step\n",
        "    # This is done at an odd multiple of resampling_interval // 2 in Anthropic's paper.\n",
        "    if autoencoder.is_dead_neuron_investigation_step(step, resampling_interval, num_resamples):\n",
        "        print(f'initiating investigation of dead neurons at step = {step}')\n",
        "        autoencoder.initiate_dead_neurons()\n",
        "\n",
        "    # check if we should look for dead neurons at this step\n",
        "    # This is done between an odd and an even multiple of resampling_interval // 2.\n",
        "    if autoencoder.is_within_neuron_investigation_phase(step, resampling_interval, num_resamples):\n",
        "        autoencoder.update_dead_neurons(autoencoder_output['latents'])\n",
        "\n",
        "    # perform neuron resampling if step is a multiple of resampling interval\n",
        "    if (step+1) % resampling_interval == 0 and step < num_resamples * resampling_interval:\n",
        "        num_dead_neurons = len(autoencoder.dead_neurons)\n",
        "        print(f'{num_dead_neurons} neurons to be resampled at step = {step}')\n",
        "        if num_dead_neurons > 0:\n",
        "            autoencoder.resample_dead_neurons(data=resourceloader.select_resampling_data(size=resampling_data_size),\n",
        "                                              optimizer=optimizer,\n",
        "                                              batch_size=batch_size)\n",
        "\n",
        "    ### ------------ log info ----------- ######\n",
        "    if (step % eval_interval == 0) or step == num_steps - 1:\n",
        "        step += 1\n",
        "        print(f'Entering evaluation mode at step = {step}')\n",
        "        autoencoder.eval()\n",
        "\n",
        "        log_dict = {'losses/reconstructed_nll': 0, # log-likelihood loss using reconstructed MLP activations\n",
        "                    'losses/l0_norm': 0, # L0-norm; average number of non-zero components of a feature activation vector\n",
        "                    'losses/reconstruction_loss': 0, # |xhat - x|^2 <-- L2-norm between MLP activations & their reconstruction\n",
        "                    'losses/l1_norm': 0, # L1-norm of feature activations\n",
        "                    'losses/autoencoder_loss': 0, # reconstruction_loss + L1-coeff * l1_loss\n",
        "                    'losses/nll_score': 0, # ratio of (nll_loss - ablated_loss) to (nll_loss - reconstructed_nll)\n",
        "                    }\n",
        "\n",
        "        # initiate a tensor containing the number of tokens on which each feature activates\n",
        "        feat_acts_count = torch.zeros(n_features, dtype=torch.float32)\n",
        "\n",
        "        # # get batches of text data and evaluate the autoencoder on MLP activations\n",
        "        #for iter in range(eval_iters):\n",
        "        #     if iter % 20 == 0:\n",
        "        #         print(f'Performing evaluation at iterations # ({iter} - {min(iter+19, eval_iters)})/{eval_iters}')\n",
        "        #    # x, y = resourceloader.get_text_batch(num_contexts=eval_batch_size)\n",
        "\n",
        "        #     _, nll_loss = gpt(x, y)\n",
        "        #     mlp_acts = gpt.mlp_activation_hooks[0]\n",
        "        #     gpt.clear_mlp_activation_hooks() # free up memory\n",
        "        #     _, ablated_loss = gpt(x, y, mode=\"replace\")\n",
        "\n",
        "        #     with torch.no_grad():\n",
        "        #         autoencoder_output = autoencoder(mlp_acts)\n",
        "        #     _, reconstructed_nll = gpt(x, y, mode=\"replace\", replacement_tensor=autoencoder_output['reconst_acts'])\n",
        "\n",
        "        #     # for each feature, calculate the TOTAL number of tokens on which it is active; shape:\n",
        "        feat_acts = autoencoder_output['latents'].to('cpu') # (eval_batch_size, block_size, n_features)\n",
        "  #     torch.add(feat_acts_count, feat_acts.count_nonzero(dim=[0, 1]), out=feat_acts_count) # (n_features, )\n",
        "\n",
        "  #     # calculat the AVERAGE number of non-zero entries in each feature vector and log all losses\n",
        "        log_dict['losses/l0_norm'] += feat_acts.count_nonzero(dim=-1).float().mean().item()\n",
        "  #     log_dict['losses/reconstructed_nll'] += reconstructed_nll.item()\n",
        "        log_dict['losses/autoencoder_loss'] += autoencoder_output['loss'].item()\n",
        "        log_dict['losses/reconstruction_loss'] += autoencoder_output['mse_loss'].item()\n",
        "        log_dict['losses/l1_norm'] += autoencoder_output['l1_loss'].item()\n",
        "        #     log_dict['losses/nll_score'] += (nll_loss - reconstructed_nll).item()/(nll_loss - ablated_loss).item()\n",
        "\n",
        "        # # compute feature densities and plot feature density histogram\n",
        "        # log_feat_acts_density = np.log10(feat_acts_count[feat_acts_count != 0]/(eval_iters * eval_batch_size * gpt.config.block_size)) # (n_features,)\n",
        "        # feat_density_historgram = make_density_histogram(log_feat_acts_density)\n",
        "\n",
        "        # # take mean of all loss values by dividing by the number of evaluation batches; also log more metrics\n",
        "        # log_dict = {key: val/eval_iters for key, val in log_dict.items()}\n",
        "        # log_dict.update(\n",
        "        #         {'training_step': step,\n",
        "        #         'training_examples': step * batch_size,\n",
        "        #         'debug/mean_dictionary_vector_length': torch.linalg.vector_norm(autoencoder.decoder.weight, dim=0).mean(),\n",
        "        #         'feature_density/min_log_feat_density': log_feat_acts_density.min().item() if len(log_feat_acts_density) > 0 else -100,\n",
        "        #         'feature_density/num_neurons_with_feature_density_above_1e-3': (log_feat_acts_density > -3).sum(),\n",
        "        #         'feature_density/num_neurons_with_feature_density_below_1e-3': (log_feat_acts_density < -3).sum(),\n",
        "        #         'feature_density/num_neurons_with_feature_density_below_1e-4': (log_feat_acts_density < -4).sum(),\n",
        "        #         'feature_density/num_neurons_with_feature_density_below_1e-5': (log_feat_acts_density < -5).sum(),\n",
        "        #         'feature_density/num_alive_neurons': len(log_feat_acts_density),\n",
        "        #         })\n",
        "        # if wandb_log:\n",
        "        #     log_dict.update({'feature_density/feature_density_histograms': wandb.Image(feat_density_historgram)})\n",
        "        #     wandb.log(log_dict)\n",
        "\n",
        "        autoencoder.train()\n",
        "        print(f'Exiting evaluation mode at step = {step}')\n",
        "\n",
        "    ### ------------ save a checkpoint ----------- ######\n",
        "    if save_checkpoint and step > 0 and (step % save_interval == 0 or step == num_steps - 1):\n",
        "        checkpoint = {\n",
        "                'autoencoder': autoencoder.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'log_dict': log_dict,\n",
        "                'config': config,\n",
        "                'feature_activation_counts': feat_acts_count, # may be used later to identify alive vs dead neurons\n",
        "                }\n",
        "        print(f\"saving checkpoint to {'/content/drive'} at training step = {step}\")\n",
        "        torch.save(checkpoint, os.path.join('/content/drive', 'ckpt.pt'))\n",
        "\n",
        "# if wandb_log:\n",
        "#     wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}