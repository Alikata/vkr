{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVr_gSckiQkm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load resnet50"
      ],
      "metadata": {
        "id": "ZnPUEMmAihit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torch\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdSjE2JwjNm7",
        "outputId": "00e8bea1-e829-4ffd-9281-eecb5725a450"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.resnet50()\n",
        "# Model\n",
        "n_classes = 2\n",
        "model = torchvision.models.resnet50(pretrained=True)\n",
        "d = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(d, n_classes)\n",
        "\n",
        "checkpoint = torch.load(\"/content/tmp_checkpoint10(11).pt\")\n",
        "model.load_state_dict(checkpoint)\n",
        "\n",
        "model.cuda()\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WScJ1zBpjUrx",
        "outputId": "86ed23db-2c0d-4fdb-dcc8-22e54094a39c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-8-6452c16bdccb>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\"/content/tmp_checkpoint10(11).pt\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load autoencoder"
      ],
      "metadata": {
        "id": "bqe53licimy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This file defines an AutoEncoder class, which also contains an implementation of neuron resampling.\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, n_inputs: int, n_latents: int, lam: float = 0.003, resampling_interval: int = 25000):\n",
        "        \"\"\"\n",
        "        n_input: Number of inputs\n",
        "        n_latents: Number of neurons in the hidden layer\n",
        "        lam: L1-coefficient for Sparse Autoencoder\n",
        "        resampling_interval: Number of training steps after which dead neurons will be resampled\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.n_inputs, self.n_latents = n_inputs, n_latents\n",
        "        self.encoder = nn.Linear(n_inputs, n_latents)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.decoder = nn.Linear(n_latents, n_inputs)\n",
        "        self.lam = lam\n",
        "        self.resampling_interval = resampling_interval\n",
        "        self.dead_neurons = None\n",
        "        self.normalize_decoder_columns()\n",
        "\n",
        "    def forward(self, x):\n",
        "        latents = self.encode(x)\n",
        "        reconstructed = self.decode(latents)\n",
        "        loss = self.calculate_loss(x, latents, reconstructed)\n",
        "\n",
        "        if self.training:\n",
        "            return {'loss': loss, 'latents': latents}\n",
        "        else:\n",
        "            return {\n",
        "                'loss': loss,\n",
        "                'latents': latents,\n",
        "                'reconst_acts': reconstructed,\n",
        "                'mse_loss': self.mse_loss(reconstructed, x),\n",
        "                'l1_loss': self.l1_loss(latents)\n",
        "            }\n",
        "\n",
        "    def encode(self, x):\n",
        "        bias_corrected_input = x - self.decoder.bias\n",
        "        return self.relu(self.encoder(bias_corrected_input))\n",
        "\n",
        "    def decode(self, encoded):\n",
        "        return self.decoder(encoded)\n",
        "\n",
        "    def calculate_loss(self, x, encoded, reconstructed):\n",
        "        mse_loss = self.mse_loss(reconstructed, x)\n",
        "        l1_loss = self.l1_loss(encoded)\n",
        "        return mse_loss + self.lam * l1_loss\n",
        "\n",
        "    def mse_loss(self, reconstructed, original):\n",
        "        return F.mse_loss(reconstructed, original)\n",
        "\n",
        "    def l1_loss(self, encoded):\n",
        "        return F.l1_loss(encoded, torch.zeros_like(encoded), reduction='sum') / encoded.shape[0]\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def get_feature_activations(self, inputs, start_idx, end_idx):\n",
        "        \"\"\"\n",
        "        Computes the activations of a subset of features in the hidden layer.\n",
        "\n",
        "        :param inputs: Input tensor of shape (..., n) where n = d_MLP. It includes batch dimensions.\n",
        "        :param start_idx: Starting index (inclusive) of the feature subset.\n",
        "        :param end_idx: Ending index (exclusive) of the feature subset.\n",
        "\n",
        "        Returns the activations for the specified feature range, reducing computation by\n",
        "        only processing the necessary part of the network's weights and biases.\n",
        "        \"\"\"\n",
        "        adjusted_inputs = inputs - self.decoder.bias  # Adjust input to account for decoder bias\n",
        "        weight_subset = self.encoder.weight[start_idx:end_idx, :].t()  # Transpose the subset of weights\n",
        "        bias_subset = self.encoder.bias[start_idx:end_idx]\n",
        "\n",
        "        activations = self.relu(adjusted_inputs @ weight_subset + bias_subset)\n",
        "\n",
        "        return activations\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def normalize_decoder_columns(self):\n",
        "        \"\"\"\n",
        "        Normalize the decoder's weight vectors to have unit norm along the feature dimension.\n",
        "        This normalization can help in maintaining the stability of the network's weights.\n",
        "        \"\"\"\n",
        "        self.decoder.weight.data = F.normalize(self.decoder.weight.data, dim=0)\n",
        "\n",
        "    def remove_parallel_component_of_decoder_grad(self):\n",
        "        \"\"\"\n",
        "        Remove the component of the gradient parallel to the decoder's weight vectors.\n",
        "        \"\"\"\n",
        "        unit_weights = F.normalize(self.decoder.weight, dim=0) # \\hat{b}\n",
        "        proj = (self.decoder.weight.grad * unit_weights).sum(dim=0) * unit_weights\n",
        "        self.decoder.weight.grad = self.decoder.weight.grad - proj\n",
        "\n",
        "    @staticmethod\n",
        "    def is_dead_neuron_investigation_step(step, resampling_interval, num_resamples):\n",
        "        \"\"\"\n",
        "        Determine if the current step is the start of a phase for investigating dead neurons.\n",
        "        According to Anthropic's specified policy, it occurs at odd multiples of half the resampling interval.\n",
        "        \"\"\"\n",
        "        return (step > 0) and step % (resampling_interval // 2) == 0 and (step // (resampling_interval // 2)) % 2 != 0 and step < resampling_interval * num_resamples\n",
        "\n",
        "    @staticmethod\n",
        "    def is_within_neuron_investigation_phase(step, resampling_interval, num_resamples):\n",
        "        \"\"\"\n",
        "        Check if the current step is within a phase where active neurons are investigated.\n",
        "        This phase occurs in intervals defined in the specified range, starting at odd multiples of half the resampling interval.\n",
        "        \"\"\"\n",
        "        return any(milestone - resampling_interval // 2 <= step < milestone\n",
        "                   for milestone in range(resampling_interval, resampling_interval * (num_resamples + 1), resampling_interval))\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def initiate_dead_neurons(self):\n",
        "        self.dead_neurons = set(range(self.n_latents))\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def update_dead_neurons(self, latents):\n",
        "        \"\"\"\n",
        "        Update the set of dead neurons based on the current feature activations.\n",
        "        If a neuron is active (has non-zero activation), it is removed from the dead neuron set.\n",
        "        \"\"\"\n",
        "        active_neurons = torch.nonzero(torch.count_nonzero(latents, dim=0), as_tuple=False).view(-1)\n",
        "        self.dead_neurons.difference_update(active_neurons.tolist())\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def resample_dead_neurons(self, data, optimizer, batch_size=8192):\n",
        "        \"\"\"\n",
        "        Resample the dead neurons by resetting their weights and biases based on the characteristics\n",
        "        of active neurons. Proceeds only if there are dead neurons to resample.\n",
        "        \"\"\"\n",
        "        if not self.dead_neurons:\n",
        "            return\n",
        "\n",
        "        device = self._get_device()\n",
        "        dead_neurons_t, alive_neurons = self._get_neuron_indices()\n",
        "        average_enc_norm = self._compute_average_norm_of_alive_neurons(alive_neurons)\n",
        "        probs = self._compute_loss_probabilities(data, batch_size, device)\n",
        "        selected_examples = self._select_examples_based_on_probabilities(data, probs)\n",
        "\n",
        "        self._resample_neurons(selected_examples, dead_neurons_t, average_enc_norm, device)\n",
        "        self._update_optimizer_parameters(optimizer, dead_neurons_t)\n",
        "\n",
        "        print('Dead neurons resampled successfully!')\n",
        "        self.dead_neurons = None\n",
        "\n",
        "    def _get_device(self):\n",
        "        return next(self.parameters()).device\n",
        "\n",
        "    def _get_neuron_indices(self):\n",
        "        dead_neurons_t = torch.tensor(list(self.dead_neurons), device=self._get_device())\n",
        "        alive_neurons = torch.tensor([i for i in range(self.n_latents) if i not in self.dead_neurons], device=self._get_device())\n",
        "        return dead_neurons_t, alive_neurons\n",
        "\n",
        "    def _compute_average_norm_of_alive_neurons(self, alive_neurons):\n",
        "        return torch.linalg.vector_norm(self.encoder.weight[alive_neurons], dim=1).mean()\n",
        "\n",
        "    def _compute_loss_probabilities(self, data, batch_size, device):\n",
        "        num_batches = (len(data) + batch_size - 1) // batch_size\n",
        "        probs = torch.zeros(len(data), device=device)\n",
        "        for i in range(num_batches):\n",
        "            batch_slice = slice(i * batch_size, (i + 1) * batch_size)\n",
        "            x_batch = data[batch_slice].to(device)\n",
        "            probs[batch_slice] = self._compute_batch_loss_squared(x_batch)\n",
        "        return probs.cpu()\n",
        "\n",
        "    def _compute_batch_loss_squared(self, x_batch):\n",
        "        latents = self.encode(x_batch)\n",
        "        reconst_acts = self.decode(latents)\n",
        "        mselosses = F.mse_loss(reconst_acts, x_batch, reduction='none').sum(dim=1)\n",
        "        l1losses = F.l1_loss(latents, torch.zeros_like(latents), reduction='none').sum(dim=1)\n",
        "        return (mselosses + self.lam * l1losses).square()\n",
        "\n",
        "    def _select_examples_based_on_probabilities(self, data, probs):\n",
        "        selection_indices = torch.multinomial(probs, num_samples=len(self.dead_neurons))\n",
        "        return data[selection_indices].to(dtype=torch.float32)\n",
        "\n",
        "    def _resample_neurons(self, examples, dead_neurons_t, average_enc_norm, device):\n",
        "        examples_unit_norm = F.normalize(examples, dim=1).to(device)\n",
        "        self.decoder.weight[:, dead_neurons_t] = examples_unit_norm.T\n",
        "\n",
        "        # Renormalize examples to have a certain norm and reset encoder weights and biases\n",
        "        adjusted_examples = examples_unit_norm * average_enc_norm * 0.2\n",
        "        self.encoder.weight[dead_neurons_t] = adjusted_examples\n",
        "        self.encoder.bias[dead_neurons_t] = 0\n",
        "\n",
        "    def _update_optimizer_parameters(self, optimizer, dead_neurons_t):\n",
        "        for i, param in enumerate(optimizer.param_groups[0]['params']):\n",
        "            param_state = optimizer.state[param]\n",
        "            if i in [0, 1]:  # Encoder weights and biases\n",
        "                param_state['exp_avg'][dead_neurons_t] = 0\n",
        "                param_state['exp_avg_sq'][dead_neurons_t] = 0\n",
        "            elif i == 2:  # Decoder weights\n",
        "                param_state['exp_avg'][:, dead_neurons_t] = 0\n",
        "                param_state['exp_avg_sq'][:, dead_neurons_t] = 0"
      ],
      "metadata": {
        "id": "iWkl5dXRimGM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## MY\n",
        "\n",
        "\"\"\"\n",
        "Train a Sparse AutoEncoder model\n",
        "\n",
        "Run on a macbook on a Shakespeare dataset as\n",
        "python train.py --dataset=shakespeare_char --gpt_ckpt_dir=out_sc_1_2_32 --eval_iters=1 --eval_batch_size=16 --batch_size=128 --device=cpu --eval_interval=100 --n_features=1024 --resampling_interval=150 --wandb_log=True\n",
        "\"\"\"\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "\n",
        "## hyperparameters\n",
        "\n",
        "# training\n",
        "n_features = 8096\n",
        "batch_size = 32 # batch size for autoencoder training\n",
        "l1_coeff = 3e-3\n",
        "learning_rate = 3e-4\n",
        "resampling_interval = 25000 # number of training steps after which neuron resampling will be performed\n",
        "num_resamples = 4 # number of times resampling is to be performed; it is done 4 times in Anthropic's paper\n",
        "resampling_data_size = 819200\n",
        "# evaluation\n",
        "eval_batch_size = 16 # batch size (number of GPT contexts) for evaluation\n",
        "eval_iters = 200 # number of iterations in the evaluation loop\n",
        "eval_interval = 1000 # number of training steps after which the autoencoder is evaluated\n",
        "# I/O\n",
        "save_checkpoint = True # whether to save model, optimizer, etc or not\n",
        "save_interval = 10000 # number of training steps after which a checkpoint will be saved\n",
        "out_dir = 'out' # directory containing trained autoencoder model weights\n",
        "# wandb logging\n",
        "wandb_log = True\n",
        "# system\n",
        "device = 'cuda'\n",
        "# reproducibility\n",
        "seed = 1442\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "config_keys = [k for k,v in globals().items() if not k.startswith('_') and isinstance(v, (int, float, bool, str))]\n",
        "#exec(open('configurator.py').read()) # overrides from command line or config file\n",
        "config = {k: globals()[k] for k in config_keys} # will be useful for logging\n",
        "# -----------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "t5JRQiCVVczH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = AutoEncoder(n_inputs = 2048,\n",
        "                            n_latents = n_features,\n",
        "                            lam = l1_coeff,\n",
        "                            resampling_interval = resampling_interval).to(device)\n",
        "autoencoder.load_state_dict(torch.load('/content/drive/MyDrive/ckpt_final.pt', weights_only=True)['autoencoder'])\n",
        "autoencoder.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMCJg83tkP0B",
        "outputId": "3aa42601-f461-4203-f2a1-ee285952ace7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AutoEncoder(\n",
              "  (encoder): Linear(in_features=2048, out_features=8096, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (decoder): Linear(in_features=8096, out_features=2048, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load data"
      ],
      "metadata": {
        "id": "q8E7G-u12ba4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install kaggle\n",
        "# !mkdir ~/.kaggle\n",
        "# !touch ~/.kaggle/kaggle.json\n",
        "\n",
        "# api_token = {\"username\":\"username\",\"key\":\"api-key\"}\n",
        "\n",
        "# import json\n",
        "\n",
        "# with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "#     json.dump(api_token, file)\n",
        "\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n",
        "# !kaggle datasets download -d jessicali9530/celeba-dataset\n",
        "\n",
        "# !unzip celeba-dataset.zip -d celeba-dataset\n"
      ],
      "metadata": {
        "id": "fM9fUbrzWifs"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PolinaKirichenko/deep_feature_reweighting.git"
      ],
      "metadata": {
        "id": "WDAkcmax3UHo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2b58842-e353-47bc-e9f3-dd80ceda2753"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep_feature_reweighting'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 55 (delta 19), reused 13 (delta 13), pack-reused 30 (from 1)\u001b[K\n",
            "Receiving objects: 100% (55/55), 2.51 MiB | 5.33 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp deep_feature_reweighting/celeba_metadata.csv celeba-dataset/img_align_celeba/metadata.csv"
      ],
      "metadata": {
        "id": "d68sW0uv3WQq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from deep_feature_reweighting.wb_data import WaterBirdsDataset, get_loader, get_transform_cub, log_data\n",
        "\n",
        "basedir = '/content/celeba-dataset/img_align_celeba/'\n",
        "test_wb_dir='/content/celeba-dataset/img_align_celeba/'\n",
        "\n",
        "# Data\n",
        "target_resolution = (224, 224)\n",
        "train_transform = get_transform_cub(target_resolution=target_resolution, train=True, augment_data=None)\n",
        "test_transform = get_transform_cub(target_resolution=target_resolution, train=False, augment_data=None)\n",
        "\n",
        "\n",
        "trainset = WaterBirdsDataset(basedir=basedir, split=\"train\", transform=train_transform)\n",
        "testset_dict = {\n",
        "    'wb': WaterBirdsDataset(basedir=test_wb_dir, split=\"test\", transform=test_transform),\n",
        "    'wb_val': WaterBirdsDataset(basedir=test_wb_dir, split=\"val\", transform=test_transform),\n",
        "}\n",
        "''\n",
        "loader_kwargs = {'batch_size': batch_size, 'num_workers': 4, 'pin_memory': True}\n",
        "train_loader = get_loader(trainset, reweight_groups=None,\n",
        "                          reweight_classes=None, reweight_places=None, train=False, **loader_kwargs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0j49GFl2eKg",
        "outputId": "b5cf27b7-dfad-4d3b-daee-613772283fe8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "202599\n",
            "162770\n",
            "202599\n",
            "19962\n",
            "202599\n",
            "19867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader_dict = {}\n",
        "for test_name, testset_v in testset_dict.items():\n",
        "    test_loader_dict[test_name] = get_loader(\n",
        "        testset_v, train=False, reweight_groups=None,\n",
        "        reweight_classes=None, reweight_places=None, **loader_kwargs)"
      ],
      "metadata": {
        "id": "lWQe-_M32eN4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zt_upD222eQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# estimate"
      ],
      "metadata": {
        "id": "PdXpbUBlltVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deep_feature_reweighting.utils import AverageMeter, get_results\n",
        "import tqdm\n",
        "import gc"
      ],
      "metadata": {
        "id": "n9eDyEVPiL9F"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V9Tv3SIjiYGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embed(m, x):\n",
        "    x = m.conv1(x)\n",
        "    x = m.bn1(x)\n",
        "    x = m.relu(x)\n",
        "    x = m.maxpool(x)\n",
        "\n",
        "    x = m.layer1(x)\n",
        "    x = m.layer2(x)\n",
        "    x = m.layer3(x)\n",
        "    x = m.layer4(x)\n",
        "\n",
        "    x = m.avgpool(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Lg7sy45yd6PV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_and_autoencoder(m, x):\n",
        "  x = get_embed(m, x)\n",
        "  x = autoencoder(x)['reconst_acts']\n",
        "  x = m.fc(x)\n",
        "  return x"
      ],
      "metadata": {
        "id": "Bi6B8WIic2dY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_place = False\n",
        "acc_groups = {g_idx : AverageMeter() for g_idx in range(train_loader.dataset.n_groups)}\n",
        "for x, y, g, p in tqdm.tqdm(train_loader):\n",
        "    x, y, p = x.cuda(), y.cuda(), p.cuda()\n",
        "    if predict_place:\n",
        "        y = p\n",
        "\n",
        "    logits = model_and_autoencoder(model, x)\n",
        "    preds = torch.argmax(logits, axis=1)\n",
        "    correct_batch = (preds == y)\n",
        "    g = g.cpu()\n",
        "    for g_val in np.unique(g):\n",
        "        mask = g == g_val\n",
        "        n = mask.sum().item()\n",
        "        corr = correct_batch[mask].sum().item()\n",
        "        acc_groups[g_val].update(corr / n, n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H327guPAfah_",
        "outputId": "c93541f0-36b4-4acf-ea0c-0326a613d0c0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5087/5087 [03:55<00:00, 21.62it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groups = acc_groups.keys()\n",
        "\n",
        "all_correct = sum([acc_groups[g].sum for g in groups])\n",
        "all_total = sum([acc_groups[g].count for g in groups])\n",
        "print(\"mean_accuracy :\", all_correct / all_total)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLGZS3MVsk48",
        "outputId": "d46abbbf-35e9-473e-aa2f-725250299264"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_accuracy : 0.9214843030042391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jGvJSssTsk8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tixnJmG5iXch",
        "outputId": "8272bb80-eadc-44df-fcdf-692fc873e70b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu8X2VWh9BSM",
        "outputId": "95974f9f-851d-4c0d-a69f-526669aeb5d4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'wb': <torch.utils.data.dataloader.DataLoader at 0x7b644686a1d0>,\n",
              " 'wb_val': <torch.utils.data.dataloader.DataLoader at 0x7b644686ab10>}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_place = False\n",
        "acc_groups = {g_idx : AverageMeter() for g_idx in range(test_loader_dict['wb'].dataset.n_groups)}\n",
        "for x, y, g, p in tqdm.tqdm(test_loader_dict['wb']):\n",
        "    x, y, p = x.cuda(), y.cuda(), p.cuda()\n",
        "    if predict_place:\n",
        "        y = p\n",
        "\n",
        "    logits = model_and_autoencoder(model, x)\n",
        "    preds = torch.argmax(logits, axis=1)\n",
        "    correct_batch = (preds == y)\n",
        "    g = g.cpu()\n",
        "    for g_val in np.unique(g):\n",
        "        mask = g == g_val\n",
        "        n = mask.sum().item()\n",
        "        corr = correct_batch[mask].sum().item()\n",
        "        acc_groups[g_val].update(corr / n, n)\n",
        "\n",
        "groups = acc_groups.keys()\n",
        "\n",
        "all_correct = sum([acc_groups[g].sum for g in groups])\n",
        "all_total = sum([acc_groups[g].count for g in groups])\n",
        "print(\"mean_accuracy :\", all_correct / all_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_taIsexz89LX",
        "outputId": "61620f8e-8c1f-4f8e-e2dd-7ba5de4e58ba"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 624/624 [00:28<00:00, 21.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_accuracy : 0.9197475202885482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_place = False\n",
        "acc_groups = {g_idx : AverageMeter() for g_idx in range(test_loader_dict['wb_val'].dataset.n_groups)}\n",
        "for x, y, g, p in tqdm.tqdm(test_loader_dict['wb_val']):\n",
        "    x, y, p = x.cuda(), y.cuda(), p.cuda()\n",
        "    if predict_place:\n",
        "        y = p\n",
        "\n",
        "    logits = model_and_autoencoder(model, x)\n",
        "    preds = torch.argmax(logits, axis=1)\n",
        "    correct_batch = (preds == y)\n",
        "    g = g.cpu()\n",
        "    for g_val in np.unique(g):\n",
        "        mask = g == g_val\n",
        "        n = mask.sum().item()\n",
        "        corr = correct_batch[mask].sum().item()\n",
        "        acc_groups[g_val].update(corr / n, n)\n",
        "\n",
        "groups = acc_groups.keys()\n",
        "\n",
        "all_correct = sum([acc_groups[g].sum for g in groups])\n",
        "all_total = sum([acc_groups[g].count for g in groups])\n",
        "print(\"mean_accuracy :\", all_correct / all_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nCKAFsf9WaE",
        "outputId": "e20060d6-942e-469c-c1ac-19b8634190f9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 621/621 [00:28<00:00, 21.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_accuracy : 0.9171993758493985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}